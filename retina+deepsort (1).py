# -*- coding: utf-8 -*-
"""Retina+DeepSort

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sQc8Tui0zGPgJXih_egmBlngmffqETIv
"""

!pip install insightface opencv-python numpy

!pip install onnxruntime

from google.colab import files
uploaded = files.upload()

import cv2
import numpy as np
from insightface.app import FaceAnalysis
from sklearn.metrics.pairwise import cosine_similarity
from google.colab.patches import cv2_imshow

# --- Init InsightFace (RetinaFace + ArcFace) ---
face_app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
face_app.prepare(ctx_id=0, det_size=(640, 640))

# --- Load known person's face and compute embedding ---
ref_img = cv2.imread("/content/known.jpeg")  # Upload this to Colab
ref_faces = face_app.get(ref_img)

if not ref_faces:
    raise ValueError("No face found in reference image.")

ref_embedding = ref_faces[0].embedding.reshape(1, -1)

# --- Load video ---
video = cv2.VideoCapture("/content/clideo_editor_fdc275ea413b4d3aaf161c87fb14cbed.mp4")  # Upload this too
fps = int(video.get(cv2.CAP_PROP_FPS))
width = int(video.get(3))
height = int(video.get(4))

out = cv2.VideoWriter("/content/output.mp4",
                      cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

# --- Settings ---
SIMILARITY_THRESHOLD = 0.5  # Can tune this
frame_limit = 300           # To avoid displaying too many frames in Colab

frame_count = 0

while frame_count < frame_limit:
    ret, frame = video.read()
    if not ret:
        break

    faces = face_app.get(frame)
    found = False

    for face in faces:
        emb = face.embedding.reshape(1, -1)
        score = cosine_similarity(ref_embedding, emb)[0][0]

        if score > SIMILARITY_THRESHOLD:
            box = face.bbox.astype(int)
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
            cv2.putText(frame, f"Match: {score:.2f}", (box[0], box[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            found = True

    out.write(frame)

    # Show frame only if match found
    if found:
        print(f"Match found on frame {frame_count}")
        cv2_imshow(frame)

    frame_count += 1

video.release()
out.release()
print("Detection complete. Output saved to /content/output.mp4")

!pip install insightface onnxruntime opencv-python-headless lap deep_sort_realtime

import cv2
import numpy as np
import os
import datetime
from insightface.app import FaceAnalysis
from sklearn.metrics.pairwise import cosine_similarity
from deep_sort_realtime.deepsort_tracker import DeepSort
from google.colab.patches import cv2_imshow

# Initialize RetinaFace + ArcFace
face_app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])
face_app.prepare(ctx_id=0, det_size=(640, 640))

# Initialize Deep SORT
tracker = DeepSort(max_age=30)

ref_paths = [
    "/content/known.jpeg",
    "/content/known2.jpeg",
    "/content/known3.jpeg",
    "/content/known4.jpeg"
]

ref_embeddings = []
for path in ref_paths:
    img = cv2.imread(path)
    faces = face_app.get(img)
    if not faces:
        print(f"No face found in {path}")
        continue
    embedding = faces[0].normed_embedding
    ref_embeddings.append(embedding)

# Compute average embedding
avg_ref_embedding = np.mean(ref_embeddings, axis=0)

video = cv2.VideoCapture("/content/clideo_editor_fdc275ea413b4d3aaf161c87fb14cbed.mp4")
fps = int(video.get(cv2.CAP_PROP_FPS))
width, height = int(video.get(3)), int(video.get(4))

out = cv2.VideoWriter("/content/output_tracked3.mp4",
                      cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

SIM_THRESHOLD = 0.58
appearances = []  # Log (frame_num, timestamp)

frame_num = 0

while True:
    ret, frame = video.read()
    if not ret:
        break

    faces = face_app.get(frame)

    for face in faces:
        embedding = face.normed_embedding  # Already normalized by InsightFace
        score = cosine_similarity([embedding], [avg_ref_embedding])[0][0]

        if score >= SIM_THRESHOLD:
            box = face.bbox.astype(int)
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
            cv2.putText(frame, f"Person_1 ({score:.2f})", (box[0], box[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            timestamp = frame_num / fps
            appearances.append((frame_num, f"{timestamp:.2f}s"))

    out.write(frame)
    frame_num += 1

video.release()
out.release()

import pandas as pd

df = pd.DataFrame(appearances, columns=["Frame", "Timestamp", "Track ID"])
df.drop_duplicates(subset=["Track ID", "Timestamp"], inplace=True)
df.to_csv("/content/person_appearances3.csv", index=False)

df.head(10)

ref_paths = [
    "/content/1known.jpeg",
    "/content/2known.jpeg",
    "/content/known.jpeg",
    "/content/known2.jpeg",
    "/content/known3.jpeg",
    "/content/known4.jpeg",
]

ref_embeddings = []
for path in ref_paths:
    img = cv2.imread(path)
    faces = face_app.get(img)
    if not faces:
        print(f"No face found in {path}")
        continue
    embedding = faces[0].normed_embedding
    ref_embeddings.append(embedding)

# Compute average embedding
avg_ref_embedding = np.mean(ref_embeddings, axis=0)

video = cv2.VideoCapture("/content/clideo_editor_fdc275ea413b4d3aaf161c87fb14cbed.mp4")
fps = int(video.get(cv2.CAP_PROP_FPS))
width, height = int(video.get(3)), int(video.get(4))

out = cv2.VideoWriter("/content/output_2.mp4",
                      cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

SIM_THRESHOLD = 0.58
appearances = []  # Log (frame_num, timestamp)

frame_num = 0

while True:
    ret, frame = video.read()
    if not ret:
        break

    faces = face_app.get(frame)

    for face in faces:
        embedding = face.normed_embedding  # Already normalized by InsightFace
        score = cosine_similarity([embedding], [avg_ref_embedding])[0][0]

        if score >= SIM_THRESHOLD:
            box = face.bbox.astype(int)
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
            cv2.putText(frame, f"Person_1 ({score:.2f})", (box[0], box[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            timestamp = frame_num / fps
            appearances.append((frame_num, f"{timestamp:.2f}s"))

    out.write(frame)
    frame_num += 1

video.release()
out.release()

